{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649caa3b-6a25-4ed5-bb5c-da9deb465d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, TextLoader\n",
    "# from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "# from langchain_community.llms import GPT4All\n",
    "from langchain_community.vectorstores import Milvus, Chroma\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779b17f6-0c6c-46b0-97f3-ec799a2c3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installed\n",
    "\n",
    "# gpt4all\n",
    "# chromadb\n",
    "# pypdf\n",
    "\n",
    "# langchain\n",
    "# langchain_openai\n",
    "# pymilvus\n",
    "# pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25e8c6d-7bd8-40d9-ac16-ac15e91b588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://milvus.io/docs/integrate_with_langchain.md\n",
    "# https://github.com/py-pdf/benchmarks\n",
    "# Note: for best results upload .txt files\n",
    "# TODO: custom Loader that stores uid in metadata\n",
    "# TODO: limit upload size\n",
    "\n",
    "# Compare:\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/chroma/ # no filtering\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/qdrant/ # has 1G free forever; poor deployment docs\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/milvus/ # good all round\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/redis/ # easy syntax for filtering but not sure if retriever can filter\n",
    "\n",
    "# https://milvus.io/docs/integrate_with_langchain.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4361d9ec-3bff-4cd9-88d9-7517ab0b3395",
   "metadata": {},
   "source": [
    "# Document Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef6c5f9-8627-4dc6-9229-a954b811babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# custom one class loader\n",
    "# custom loader for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d4c8bb-84ca-44a6-ad6e-0604d217827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoader(BaseLoader):\n",
    "    def __init__(self, file_path: str, metadata: dict=None) -> None:\n",
    "        self.file_path = file_path\n",
    "        self.ext = file_path.split('.')[-1].lower()\n",
    "        if not metadata:\n",
    "            self.metadata = {'file_path': filepath}\n",
    "        else:\n",
    "            self.metadata = metadata\n",
    "\n",
    "    # TODO: support more file types\n",
    "    def load(self) -> list[Document]:\n",
    "        if self.ext == 'txt':\n",
    "            with open(self.file_path, encoding=\"utf-8\") as f:\n",
    "                doc = Document(\n",
    "                    page_content=f.read(),\n",
    "                    metadata=self.metadata\n",
    "                )\n",
    "        elif self.ext == 'pdf':\n",
    "            loader = PyMuPDFLoader(self.file_path)\n",
    "            doc = loader.load()[0]\n",
    "            doc.metadata = self.metadata\n",
    "        else:\n",
    "            raise Exception(f'Unable to load {self.file_path}')\n",
    "        return [doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e09fdbe-c67e-458e-9b82-aba57754d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split(path, uid, category):\n",
    "    documents = []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    try:\n",
    "        loader = CustomLoader(path, metadata={'file_path': path, 'category': category, 'uid': uid})\n",
    "        documents.extend(loader.load_and_split(text_splitter=text_splitter))\n",
    "        print(f'Loaded {path}')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494e5c20-3b70-439b-afce-0550b35f3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    './data/personal context/Interview Questions v2.txt',\n",
    "    './data/personal context/resume.pdf',\n",
    "    './data/domain knowledge/2402.03367.pdf',\n",
    "    './data/domain knowledge/foo.bar'\n",
    "]\n",
    "uids = [1, 2, 3, 4]\n",
    "categories = ['personal context'] * 2 + ['domain knowledge'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e32dafd-64fd-49af-8d75-ba6f0c0603f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ./data/personal context/Interview Questions v2.txt\n",
      "Loaded ./data/personal context/resume.pdf\n",
      "Loaded ./data/domain knowledge/2402.03367.pdf\n",
      "Unable to load ./data/domain knowledge/foo.bar\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for path, uid, category in zip(paths, uids, categories):\n",
    "    docs += load_and_split(path, uid, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456507b4-bafb-416e-8822-3f0d17009c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Document retrieval is a fundamental component of the algorithm. Traditional RAG virtual assistants rank documents\\nin the order of relevance to the query, usually by vector distances. This means that the more relevant a document\\nis in a query, the higher priority it takes being in the answer. Recently, however, developers and researchers have\\nexplored implementing different reranking methods for documents. It has been found that reranking in retrieval-\\naugmented generation plays a significant role in improving retrieval results and in increasing the accuracy, relevance,\\nand comprehensiveness of answers. [6]\\n∗Citation: Authors. Title. Pages.... DOI:000000/11111.\\narXiv:2402.03367v1  [cs.IR]  31 Jan 2024', metadata={'file_path': './data/domain knowledge/2402.03367.pdf', 'category': 'domain knowledge', 'uid': 3})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f1751-a137-4548-81e0-09f51a4391e6",
   "metadata": {},
   "source": [
    "# Vector Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b3c024-0668-4004-adb3-65a9300738c7",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6372d485-ed98-4a19-9b8b-d01c6f3f1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = GPT4AllEmbeddings()\n",
    "DIMENSION = 1024\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=DIMENSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a6adeb-d0cb-4fb3-88b9-beb21741e0c2",
   "metadata": {},
   "source": [
    "## Chroma (for local testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5be07cc8-e9eb-4159-9ecf-5b64dc8b46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Local Chroma\n",
    "# vector_store = Chroma.from_documents(documents=[documents_pc, documents_dk], embedding=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f8314-7549-4879-90fa-4953a0694ce9",
   "metadata": {},
   "source": [
    "## Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb73b3c-4c70-47d1-99be-41ba55ace3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run Milvus app in docker\n",
    "# https://milvus.io/docs/install_standalone-docker-compose.md\n",
    "# docker compose -f milvus-standalone-docker-compose.yml up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e865af-0dc2-444a-8578-2417c6d1502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = 'lockedinai'\n",
    "CONNECTION_ARGS = {'uri': 'http://localhost:19530'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9c3f9-314c-4e45-94b6-b69434da6110",
   "metadata": {},
   "source": [
    "### Legacy ORM module\n",
    "\n",
    "https://milvus.io/api-reference/pymilvus/v2.4.x/ORM/Connections/connect.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36487006-102d-4df0-9a97-2668df411ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPC error: [drop_database], <MilvusException: (code=65535, message=can not drop default database)>, <Time:{'RPC start': '2024-04-14 03:41:36.016048', 'RPC error': '2024-04-14 03:41:36.017150'}>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('default', <pymilvus.client.grpc_handler.GrpcHandler object at 0x15276aea0>)]\n",
      "['default']\n",
      "['lockedinai']\n",
      "UserInfo groups:\n",
      "- UserItem: <username:root>, <roles:()>\n",
      "{'collection_name': 'lockedinai', 'auto_id': True, 'num_shards': 1, 'description': '', 'fields': [{'field_id': 100, 'name': 'uid', 'description': '', 'type': <DataType.INT64: 5>, 'params': {}, 'is_partition_key': True}, {'field_id': 101, 'name': 'category', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'field_id': 102, 'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'field_id': 103, 'name': 'pk', 'description': '', 'type': <DataType.INT64: 5>, 'params': {}, 'auto_id': True, 'is_primary': True}, {'field_id': 104, 'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 1024}}], 'aliases': [], 'collection_id': 449067066124558708, 'consistency_level': 1, 'properties': {}, 'num_partitions': 64, 'enable_dynamic_field': False}\n",
      "<MilvusException: (code=65535, message=can not drop default database)>\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, db, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "\n",
    "connections.connect(alias='default', uri=CONNECTION_ARGS['uri'])\n",
    "\n",
    "# info\n",
    "connections_ = connections.list_connections()\n",
    "dbs = db.list_database()\n",
    "collections = utility.list_collections()\n",
    "users = utility.list_users(True)\n",
    "print(connections_)\n",
    "print(dbs)\n",
    "print(collections)\n",
    "print(users)\n",
    "\n",
    "try: # new collection\n",
    "    schema = CollectionSchema([\n",
    "        FieldSchema(\"id\", DataType.INT64, is_primary=True),\n",
    "        FieldSchema(\"vector\", DataType.FLOAT_VECTOR, dim=5)\n",
    "    ])\n",
    "    collection = Collection(name='lockedinai', schema=schema)\n",
    "    index_params = {\n",
    "        \"index_type\": \"AUTOINDEX\",\n",
    "        \"metric_type\": \"COSINE\",\n",
    "    }\n",
    "    collection.create_index(\n",
    "        field_name=\"vector\", \n",
    "        index_params=index_params, \n",
    "        timeout=None\n",
    "    )\n",
    "except: # exisitng collection\n",
    "    collection = Collection(name='lockedinai')\n",
    "\n",
    "collection.load()\n",
    "\n",
    "print(collection.describe())\n",
    "\n",
    "# clean\n",
    "for database in dbs:\n",
    "    try:\n",
    "        db.drop_database(database)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "for collection in collections:\n",
    "    utility.drop_collection(collection)\n",
    "for connection in connections_:\n",
    "    connections.disconnect(connection[0])\n",
    "    connections.remove_connection(connection[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b1daf-55a2-46f5-a29c-5a9053910458",
   "metadata": {},
   "source": [
    "### Newer MilvusClient module (hides ORM complexity)\n",
    "\n",
    "https://milvus.io/api-reference/pymilvus/v2.4.x/MilvusClient/Client/MilvusClient.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae5a29cc-3ca7-4b70-9ef5-6f9caecc1a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lockedinai']\n",
      "['vector']\n",
      "['_default']\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "\n",
    "client = MilvusClient(uri=CONNECTION_ARGS['uri']) # WARNING: remember to close\n",
    "client.create_collection(\n",
    "    COLLECTION_NAME,\n",
    "    DIMENSION,\n",
    "    primary_field_name=\"id\",\n",
    "    id_type=DataType.INT64,\n",
    "    vector_field_name=\"vector\",\n",
    "    metric_type=\"COSINE\",\n",
    "    auto_id=False,\n",
    ")\n",
    "\n",
    "# info\n",
    "collections = client.list_collections()\n",
    "indexes = client.list_indexes(collections[0])\n",
    "partitions = client.list_partitions(collections[0])\n",
    "print(collections)\n",
    "print(indexes)\n",
    "print(partitions)\n",
    "\n",
    "# clean\n",
    "for collection in collections:\n",
    "    client.drop_collection(collection_name=collections[0])\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f6787-a86f-4c74-b54b-6930f8e514b9",
   "metadata": {},
   "source": [
    "### LangChain Milvus module\n",
    "\n",
    "https://python.langchain.com/docs/integrations/vectorstores/milvus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc9c163-3804-4c30-9993-0546756ab2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if collection has never been initialized\n",
    "docs_seed = [\n",
    "    Document(page_content='', metadata={'uid': 00000000, 'category': 'domain knowledge'}),\n",
    "    Document(page_content='', metadata={'uid': 00000000, 'category': 'personal context'})\n",
    "]\n",
    "\n",
    "vector_store = Milvus.from_documents(\n",
    "    docs_seed, # seed\n",
    "    embedding,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_args=CONNECTION_ARGS,\n",
    "    drop_old=True, # WARNING: deletes old collection\n",
    "    partition_key_field=\"uid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c195ac6c-7735-4335-8477-3517a3ac66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if collections has been initialized\n",
    "vector_store = Milvus(\n",
    "    embedding,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_args=CONNECTION_ARGS,\n",
    "    drop_old=False, \n",
    "    auto_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98949a52-3bb7-4f99-a4eb-022d9f6af7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[449067066123093172,\n",
       " 449067066123093173,\n",
       " 449067066123093174,\n",
       " 449067066123093175,\n",
       " 449067066123093176,\n",
       " 449067066123093177,\n",
       " 449067066123093178,\n",
       " 449067066123093179,\n",
       " 449067066123093180,\n",
       " 449067066123093181,\n",
       " 449067066123093182,\n",
       " 449067066123093183,\n",
       " 449067066123093184,\n",
       " 449067066123093185,\n",
       " 449067066123093186,\n",
       " 449067066123093187,\n",
       " 449067066123093188,\n",
       " 449067066123093189,\n",
       " 449067066123093190,\n",
       " 449067066123093191,\n",
       " 449067066123093192,\n",
       " 449067066123093193,\n",
       " 449067066123093194,\n",
       " 449067066123093195,\n",
       " 449067066123093196,\n",
       " 449067066123093197]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.upsert(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8c34f55-7497-43cf-9bd9-19cfc282e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lockedinai']\n",
      "[('31ddd023f68d443795bfa7c21ab7c537', None), ('7f00684f04f04d4985962b6cc0d188aa', <pymilvus.client.grpc_handler.GrpcHandler object at 0x15532f710>), ('default', <pymilvus.client.grpc_handler.GrpcHandler object at 0x15532e810>)]\n"
     ]
    }
   ],
   "source": [
    "connections.connect(alias='default', uri=CONNECTION_ARGS['uri'])\n",
    "print(utility.list_collections())\n",
    "print(connections.list_connections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0110fef-1552-47e0-8f74-eb721270d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='RAG-FUSION: A NEW TAKE ON RETRIEVAL-AUGMENTED\\nGENERATION ∗\\nZackary Rackauckas\\nInfineon Technologies\\nSan Jose, CA\\nzackary.rackauckas@infineon.com\\nABSTRACT\\nInfineon has identified a need for engineers, account managers, and customers to rapidly obtain\\nproduct information. This problem is traditionally addressed with retrieval-augmented generation\\n(RAG) chatbots, but in this study, I evaluated the use of the newly popularized RAG-Fusion method.\\nRAG-Fusion combines RAG and reciprocal rank fusion (RRF) by generating multiple queries,\\nreranking them with reciprocal scores and fusing the documents and scores. Through manually\\nevaluating answers on accuracy, relevance, and comprehensiveness, I found that RAG-Fusion was\\nable to provide accurate and comprehensive answers due to the generated queries contextualizing the\\noriginal query from various perspectives. However, some answers strayed off topic when the generated', metadata={'uid': 3, 'category': 'domain knowledge', 'pk': 449067066123093194}),\n",
       " Document(page_content='augmented generation answers a user’s questions related to the purpose of the virtual assistant. The method combines\\ntext generation from large language models (LLMs) and document retrieval from databases of related documents to\\ngenerate accurate, relevant, and comprehensive responses. (Yu 2022) Large language models are advanced natural\\nlanguage processing systems trained on large sets of data that process and generate text. While they are designed to\\nhandle tasks like machine translation, summarization, and conversational interactions, RAG models can also leverage\\nthem for information retrieval. [2] RAG has shown remarkable success in several knowledge-intensive natural language\\nprocessing tasks including accurate trivia question answering, highly accurate fact verification, and accurately answering\\nmiddle school math questions. [3] [4] In addition, retrieval-augmented generation reduces misinformation typically\\nproduced by large language models and non-RAG chatbots. [5]', metadata={'uid': 3, 'category': 'domain knowledge', 'pk': 449067066123093196})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.as_retriever(\n",
    "    search_kwargs={\n",
    "        'expr': 'category == \"domain knowledge\" and uid == 3',\n",
    "        'k': 2,\n",
    "    }\n",
    ").get_relevant_documents(\"explain ragfusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b55d0fec-c9d9-40db-bad0-455ad29e2dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Deep Learning Research Scientist\\nJan 2020 - Sept 2021\\nBoston Fusion | Lexington, MA\\nJuggled several SBIR and DoD research projects. Technical mentor for new hires. Gave company-wide technical presentations on\\ntopics such as Reinforcement Learning and Graph Convolutional Networks.\\nKey Accomplishments\\n●\\nDevised a reinforcement learning OpenAI-Gym-like framework for ROS (Robotics Operating System); trained a Dueling\\nDouble DQN with Prioritized Experience Replay agent to successfully navigate a UAV to a target destination while\\nsimultaneously avoiding moving obstacles.\\n●\\nImproved acoustic classification of spectrograms and MFCCs with ResNet architecture increasing 5-fold cross validation\\naccuracy by 5%; upgraded the framework from single-label to multi-label classification; developed a Convolutional\\nAutoencoder to detect anomalous acoustic signals; developed a Siamese Network to compare in-distribution data with\\nout-of-distribution new acoustic signals.\\n●', metadata={'uid': 2, 'category': 'personal context', 'pk': 449067066123093190}),\n",
       " Document(page_content='Python ⊇{jupyter, pytorch, tensorflow, sklearn, kubeflow, spacy, numpy, scipy, pandas, matplotlib, opencv, pymysql, flask, ...}\\nMachine Learning ⊇{boosting, bagging, GLMs, decision trees, SVM, PCA, naive bayes, KNN, Gaussian Mixture Models, …}\\nDeep Learning ⊇{transformers, NLP, CNN, reinforcement learning, autoencoders, gen ai, siamese nets, graph neural nets, ...}\\nGit | Google Cloud | Docker | SQL | React | Javascript | HTML | CSS | Bash | R | Java | SAS | CUDA | ROS | MATLAB', metadata={'uid': 2, 'category': 'personal context', 'pk': 449067066123093193})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.as_retriever(\n",
    "    # search_type=\"similarity_score_threshold\", NotImplemented\n",
    "    search_kwargs={\n",
    "        'expr': 'category == \"personal context\" and uid == 2',\n",
    "        'k': 2,\n",
    "        # 'score_threshold': 0.1, # NotImplemented\n",
    "    }\n",
    ").get_relevant_documents(\"explain ragfusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c91f90d7-b69c-4462-9ff1-4522a898a145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vector_store.col.search??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80339dfd-b394-4cf0-a519-32b8998868e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.as_retriever??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2041b42-f843-4047-a4be-931a0a326923",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c104eef-1009-4ec3-af6b-dc373286c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = GPT4All(\n",
    "#     model=\"./mistral-7b-openorca.gguf2.Q4_0\",\n",
    "#     max_tokens=2048,\n",
    "#     temp=1, # 1) exp(x_i/T) / sum(exp(x_j/T))\n",
    "#     # top_k=100, # 2) after temp, sort then select top k, normalize\n",
    "#     # top_p=.5, # 3) after top_k, select until cum prob is reached, normalize\n",
    "#     repeat_penalty=1.18,\n",
    "#     repeat_last_n=64,\n",
    "#     n_batch=8,\n",
    "#     n_predict=None,\n",
    "#     streaming=False,\n",
    "# )\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a1c01e3-e6ca-490e-85db-571b165fc0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='RAG fusion is a gene fusion technique used in molecular biology to study gene expression and regulation. It involves combining the regulatory region of one gene with the coding region of another gene to create a chimeric gene with altered expression patterns. This technique can help researchers understand how genes are regulated and how changes in gene expression can lead to disease. The RAG fusion process typically involves cloning the regulatory region of one gene and the coding region of another gene into a plasmid vector, which is then transfected into cells for expression studies. By studying the expression patterns of the chimeric gene, researchers can gain insights into the functions of the individual genes and how they work together in various biological processes.', response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 25, 'total_tokens': 165}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-f75eba3d-a780-4eee-8797-2948bd01e2e4-0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without RAG\n",
    "question = \"Teach me how RAG fusion works.\"\n",
    "llm.invoke(f\"You are in an interview.\\nQuestion: {question}\\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f46049b-7e38-4486-8901-685bdf3166e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAG-Fusion is a new approach that combines retrieval-augmented generation (RAG) with reciprocal rank fusion (RRF) to improve the accuracy and comprehensiveness of answers provided by virtual assistants or chatbots. In traditional RAG methods, documents are ranked by relevance to the query based on vector distances. RAG-Fusion, on the other hand, generates multiple queries, reranks them using reciprocal scores, and then fuses the documents and scores to provide more contextualized answers.\\n\\nThrough manual evaluation of answers in terms of accuracy, relevance, and comprehensiveness, it has been found that RAG-Fusion can provide more accurate and comprehensive answers compared to traditional methods. By generating multiple queries and considering different perspectives, RAG-Fusion helps to contextualize the original query, leading to more informative responses.\\n\\nOverall, RAG-Fusion represents a significant advancement in artificial intelligence and natural language processing applications, particularly in the realm of virtual assistants and chatbots. It showcases the potential for improving information retrieval and enhancing the overall user experience in obtaining product information or other types of data quickly and effectively.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = 3\n",
    "question = \"Teach me about RAG fusion.\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"You are being interviewed.\n",
    "\n",
    "For technical questions, feel free to refer to \"Domain Knowledge\".\n",
    "For behavioral questions, feel free to refer to \"Personal Context\"; use STAR if there is an opportunity.\n",
    "\n",
    "Domain Knowledge: {domain_knowledge}\n",
    "\n",
    "Personal Context: {personal_context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "retriever_dk = vector_store.as_retriever(\n",
    "    # search_type=\"similarity_score_threshold\", # NotImplemented,\n",
    "    search_kwargs={\n",
    "        'expr': f'category == \"domain knowledge\" and uid == {uid}',\n",
    "        'k': 4,\n",
    "        # 'score_threshold': 0.1, # NotImplemented\n",
    "    }\n",
    ")\n",
    "\n",
    "retriever_pc = vector_store.as_retriever(\n",
    "    # search_type=\"similarity_score_threshold\", # NotImplemented\n",
    "    search_kwargs={\n",
    "        'expr': f'category == \"personal context\" and uid == {uid}',\n",
    "        'k': 4,\n",
    "        # 'score_threshold': 0.1, # NotImplemented\n",
    "    }\n",
    ")\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"personal_context\": retriever_pc, \"domain_knowledge\": retriever_dk, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03c013fd-e37d-42be-bded-61325057bec9",
   "metadata": {},
   "source": [
    "How to Improve Quality\n",
    "\n",
    "easy\n",
    "- chunking parameters\n",
    "- model parameters\n",
    "- prompt engineering\n",
    "- two stage search (pull whole paragraph)\n",
    "\n",
    "medium\n",
    "- rag fusion\n",
    "- finetuning generator (may mess up model weights if done incorrectly)\n",
    "\n",
    "hard\n",
    "- finetuning retriever (requires labeled q-a data)\n",
    "\n",
    "Next Steps\n",
    "- deployment\n",
    "- add/remove docs from db\n",
    "- add source / page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
